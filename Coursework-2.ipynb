{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "CDM Project: iInsureU123 - k-Anonymity and Anonymize the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overview\n",
    "In the notebook, we will implement functions to produce a k-anonymous customer information dataset provided by an insurance company, iInsureU123. Considering that the dataset would be made available to access by the public, attributes that contain extremely sensitive information (i.e. bank account) will be hidden from the dataset for the safety concern. Quasi-identifiers and sensitive attributes of values will be replaced with aggregated quantities to prevent sampled individuals from being identified. In addition, cryptographic hashing function will be applied to transform certain sensitive data to hash values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the project, we will use the Pandas to load dataset as a data frame. Other modules will be used have been listed as below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced9379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages loading\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import hashlib\n",
    "import random, string\n",
<<<<<<< HEAD
    "from cryptography.fernet import Fernet"
=======
    "import pycountry_convert as pc  #pip install pycountry-convert from terminal first"
>>>>>>> ba97166e55675867d131fe99430ad745ff435d02
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the \"customer_information\" in csv as a dataframe with Pandas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bfb15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and target\n",
    "df = pd.read_csv('customer_information.csv') #change to own source's directory"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset are used for research on the association of the gene DRD4 and travelling from educational or geographical perspective. However, individual height and weight may be not helpful for the research purpose. We decide to convert height and weight into BMI for both research purposes and privacy-preserving reasons."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc336c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert just colums \"weight\" and \"height\" into numeric.\n",
    "df[\"weight\"] = pd.to_numeric(df[\"weight\"])\n",
    "df[\"height\"] = pd.to_numeric(df[\"height\"])\n",
    "df['heightsquared']=df['height']**2\n",
    "\n",
    "#df.insert(1,\"BMI\",[])\n",
    "df['bmi']=df['weight']/df['heightsquared']\n",
    "df['bmi']=df['bmi'].apply(lambda x:round(x,2))\n",
    "\n",
    "# delete the column 'weight','height'and 'heightsquared'\n",
    "del df['weight']\n",
    "del df['height']\n",
    "del df['heightsquared']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following section, values of quasi identifiers and sensitive attributes in k-anonymous group will be banded. For example, birthdate will be converted to banded age groups; participants will be categorized into light, intermediate and heavy smokers according to average cigarettes smoked per week; consumption of drinks will be categorized to low-level, moderate and high-level alcoholic consumption. Additionally, we will transform country of birth for each participant to continents accordingly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4811011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a function to convert birthdate to age group\n",
    "# Years of birth\n",
    "birthdate=pd.to_datetime(df.birthdate)\n",
    "df['birth_year'] = pd.DatetimeIndex(birthdate).year\n",
    "\n",
    "# Age\n",
    "def from_birthdate_to_age(birth_date):\n",
    "    now=pd.Timestamp('now')\n",
    "    now_year,now_month,now_day = now.year, now.month, now.day\n",
    "    birth_date = pd.to_datetime(birth_date)\n",
    "    birth_year, birth_month, birth_day = birth_date.year, birth_date.month, birth_date.day\n",
    "    age = now_year - birth_year\n",
    "    if now_month >= birth_month:\n",
    "        if now_day >= birth_day:\n",
    "            age = now_year - birth_year + 1\n",
    "    return (age)\n",
    "\n",
    "df['age'] = df['birthdate'].apply(from_birthdate_to_age)\n",
    "\n",
    "# Banding age to groups\n",
    "bins_age = [0, 20, 30, 40, 50, 60, 80]\n",
    "labels_age= ['<20','20-30','30-40','40-50','50-60','60-70']\n",
    "df['age_groups'] = pd.cut(df.age, bins = bins_age, labels = labels_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding smoking per week\n",
    "## we are defining smoking <=40 cig per week as light smokers, 40-175 as intermediate smokers, >175 as heavy smokers\n",
    "### https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2865193/\n",
    "#### https://pubmed.ncbi.nlm.nih.gov/1614993/\n",
    "bins_smok= [0, 40, 175, 500]\n",
    "labels_smok=['light smokers','intermediate smokers','heavy smokers']\n",
    "df['smoking_status'] = pd.cut(df.avg_n_cigret_per_week, bins = bins_smok, labels = labels_smok)\n",
    "\n",
    "# Banding avg_n_drinks_per_week\n",
    "## 0-3.9 as low-level alc consumption, 4-6.9 as moderate alc consumption,7-10 as high-level alc consumption\n",
    "bins_alc = [0,4,7,10]\n",
    "label_alc = ['low', 'moderate', 'high']\n",
    "df['level of drinking_status'] = pd.cut(df.avg_n_drinks_per_week, bins = bins_alc, labels = label_alc, right = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a327fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding 'BMI' to groups\n",
    "## 0-18.5 as underweight, 18.5-24.9 as healthy,24.9 and over as overweight\n",
    "bins_bmi = [0,18.5,24.9,50]\n",
    "label_bmi = ['underweight', 'healthy', 'overweight']\n",
    "df['level of bmi'] = pd.cut(df.bmi, bins = bins_bmi, labels = label_bmi, right = False)\n",
    "\n",
    "# Banding countries visited to groups\n",
    "bins_countries = [1, 18, 34, 50]\n",
    "labels_countries= ['2-18','19-34','35-50']\n",
    "df['countries_visited'] = pd.cut(df.n_countries_visited, bins = bins_countries, labels = labels_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b37199",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Country_of_birth Clearing Up\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Korea'], 'South Korea')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Palestinian Territory'], 'Jordan')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Saint Barthelemy'], 'Dominican Republic')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Saint Helena'], 'South Africa')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Reunion'], 'Mauritius')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Svalbard and Jan Mayen'], 'Greenland')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['United States Minor Outlying Islands'], 'United States')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Antarctica (the territory South of 60 deg S)'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Western Sahara'], 'Morocco')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Svalbard & Jan Mayen Islands'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Libyan Arab Jamahiriya'], 'Libya')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Pitcairn Islands'], 'Fiji')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Slovakia (Slovak Republic)'], 'Slovakia')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Bouvet Island (Bouvetoya)'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Holy See (Vatican City State)'], 'Italy')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Timor-Leste'], 'Indonesia')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace([\"Cote d'Ivoire\"], 'Ghana')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['British Indian Ocean Territory (Chagos Archipelago)'], 'India')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace([\"Netherlands Antilles\"], \"Netherlands\")\n",
    "\n",
    "# Group original countries to continent\n",
    "def country_to_continent(country_of_birth):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_of_birth)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "df['continent_of_birth'] = df['country_of_birth'].apply(country_to_continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the section below, we will create pseudonyms to anonymize direct sensitive identifiers (e.g. names, national insurance numbers). Secure Hashing Algorithm (SHA) will be used to map personal identifiers into a non-identifiable strings. In addition to SHA, we also add a salt i.e. random number generated by the computer to enhance the security."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab47490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/l3fznfyj3qg7ldmg03cy8_z80000gn/T/ipykernel_49112/2780082543.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['hash']=df['hash']\n",
      "/var/folders/z8/l3fznfyj3qg7ldmg03cy8_z80000gn/T/ipykernel_49112/2780082543.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['salt']=salt\n"
     ]
    }
   ],
   "source": [
    "#SHA ----------------------------------------------------------------\n",
    "\n",
    "#Salt generator\n",
    "def randomword(length):\n",
    "   letters = string.ascii_lowercase #generates lowercase letters\n",
    "   return ''.join(random.choice(letters) for i in range(length)) #generates salt from letters\n",
    "\n",
    "df['NI_enc']=df['national_insurance_number'].str.encode('utf-8') #utf encoding needed for sha function\n",
    "\n",
    "key='password123'.encode('utf-8') #encoding key\n",
    "\n",
    "#Hash function\n",
    "hashes=[]\n",
    "salt=[]\n",
    "for i in range(len(df['NI_enc'])):\n",
    "    salt.append(randomword(10).encode('utf-8'))\n",
    "    hashes.append(hashlib.sha1(key+salt[i]+df['NI_enc'][i]).hexdigest()) #hash function applied \n",
    "\n",
    "df['hash']=hashes\n",
    "df['postcode_split'] = df['postcode'].str.split().str[0] \n",
    "hash_cols=['given_name','surname','phone_number','national_insurance_number','blood_group','postcode','birthdate','age','bank_account_number','birth_year','avg_n_drinks_per_week','avg_n_cigret_per_week','n_countries_visited','bmi','country_of_birth']\n",
    "\n",
    "#Lookup table generation\n",
    "secure_df=df[hash_cols]\n",
    "secure_df['hash']=df['hash']\n",
    "secure_df['salt']=salt\n",
    "new_cust=df.drop(columns=hash_cols)\n",
    "new_cust=new_cust.drop(columns='NI_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-anonymity is computed based on processed data in order to secure the dataset's confidentiality in information sharing in public. In the situation, the database is said to become K Anonymous. The anonymised dataset will be used for researchers at Imperial and collaborators in government for the analysis. Therefore, we calculate k-anonyminity for both sides."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d26e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Imperial K-anonyminity is: 4\n",
      "The Government K-anonyminity is: 1\n"
     ]
    }
   ],
   "source": [
    "#K-anonyminity - Currently freezes when adding any more quasi_identifiers\n",
    "quasi_identifiers_imp=['countries_visited','cc_status','gender']\n",
    "k_df_imp=new_cust.groupby(quasi_identifiers_imp,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Imperial K-anonyminity is: {min(k_df_imp[\"Count\"])}')\n",
    "\n",
    "#K-anonyminity - Currently freezes when adding any more quasi_identifiers\n",
    "quasi_identifiers_gov=['cc_status','continent_of_birth']\n",
    "k_df_gov=new_cust.groupby(quasi_identifiers_gov,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Government K-anonyminity is: {min(k_df_gov[\"Count\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a735b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into csv\n",
    "df.to_csv('k_df_gov.csv')\n",
    "df.to_csv('k_df_imp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d1b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key generation \n",
    "key = Fernet.generate_key()\n",
    "\n",
    "# string the key in a file\n",
    "with open ('filekey.key', 'wb') as filekey:\n",
    "    filekey.write(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb49bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the key \n",
    "with open ('filekey.key', 'rb') as filekey:\n",
    "    key = filekey.read()\n",
    "\n",
    "# using the generated key \n",
    "fernet = Fernet (key)\n",
    "\n",
    "# opening the original file to encrypt\n",
    "with open('k_df_gov.csv', 'rb') as file:\n",
    "    original = file.read()\n",
    "\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the encrypted data\n",
    "with open ('k_df_gov.csv', 'wb') as encrypted_file:\n",
    "    encrypted_file.write(encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889c1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the key \n",
    "with open ('filekey.key', 'rb') as filekey:\n",
    "    key = filekey.read()\n",
    "\n",
    "# using the generated key \n",
    "fernet = Fernet (key)\n",
    "\n",
    "# opening the original file to encrypt\n",
    "with open('k_df_imp.csv', 'rb') as file:\n",
    "    original = file.read()\n",
    "\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the encrypted data\n",
    "with open ('k_df_imp.csv', 'wb') as encrypted_file:\n",
    "    encrypted_file.write(encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6918e88e",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidToken",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cryptography/fernet.py:102\u001b[0m, in \u001b[0;36mFernet._get_unverified_token_data\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     data \u001b[39m=\u001b[39m base64\u001b[39m.\u001b[39;49murlsafe_b64decode(token)\n\u001b[1;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, binascii\u001b[39m.\u001b[39mError):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/base64.py:133\u001b[0m, in \u001b[0;36murlsafe_b64decode\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    132\u001b[0m s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mtranslate(_urlsafe_decode_translation)\n\u001b[0;32m--> 133\u001b[0m \u001b[39mreturn\u001b[39;00m b64decode(s)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/base64.py:87\u001b[0m, in \u001b[0;36mb64decode\u001b[0;34m(s, altchars, validate)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39mraise\u001b[39;00m binascii\u001b[39m.\u001b[39mError(\u001b[39m'\u001b[39m\u001b[39mNon-base64 digit found\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m binascii\u001b[39m.\u001b[39;49ma2b_base64(s)\n",
      "\u001b[0;31mError\u001b[0m: Incorrect padding",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidToken\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     encrypted \u001b[39m=\u001b[39m enc_file\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# decrypting the file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m decrypted \u001b[39m=\u001b[39m fernet\u001b[39m.\u001b[39;49mdecrypt(encrypted)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# opening the file in write mode and\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# writing the decrypted data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hailsgugu/code/Coursework-2/Coursework-2.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mk_df_gov.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m dec_file:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cryptography/fernet.py:75\u001b[0m, in \u001b[0;36mFernet.decrypt\u001b[0;34m(self, token, ttl)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecrypt\u001b[39m(\u001b[39mself\u001b[39m, token: \u001b[39mbytes\u001b[39m, ttl: typing\u001b[39m.\u001b[39mOptional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbytes\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     timestamp, data \u001b[39m=\u001b[39m Fernet\u001b[39m.\u001b[39;49m_get_unverified_token_data(token)\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m ttl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         time_info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/cryptography/fernet.py:104\u001b[0m, in \u001b[0;36mFernet._get_unverified_token_data\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    102\u001b[0m     data \u001b[39m=\u001b[39m base64\u001b[39m.\u001b[39murlsafe_b64decode(token)\n\u001b[1;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, binascii\u001b[39m.\u001b[39mError):\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidToken\n\u001b[1;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mor\u001b[39;00m data[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0x80\u001b[39m:\n\u001b[1;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidToken\n",
      "\u001b[0;31mInvalidToken\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# decrypt the encrypted file \n",
    "# using the key\n",
    "fernet = Fernet(key)\n",
    " \n",
    "# opening the encrypted file\n",
    "with open('k_df_gov.csv', 'rb') as enc_file:\n",
    "    encrypted = enc_file.read()\n",
    " \n",
    "# decrypting the file\n",
    "decrypted = fernet.decrypt(encrypted)\n",
    " \n",
    "# opening the file in write mode and\n",
    "# writing the decrypted data\n",
    "with open('k_df_gov.csv', 'wb') as dec_file:\n",
    "    dec_file.write(decrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4662930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the key\n",
    "fernet = Fernet(key)\n",
    " \n",
    "# opening the encrypted file\n",
    "with open('k_df_imp.csv', 'rb') as enc_file:\n",
    "    encrypted = enc_file.read()\n",
    " \n",
    "# decrypting the file\n",
    "decrypted = fernet.decrypt(encrypted)\n",
    " \n",
    "# opening the file in write mode and\n",
    "# writing the decrypted data\n",
    "with open('k_df_imp.csv', 'wb') as dec_file:\n",
    "    dec_file.write(decrypted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c84df20ab1ac10669529321b7ccb4b2c6d7ae7eb8b375dacb72b7198d4c273e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
