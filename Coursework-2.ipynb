{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "488e4faa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CDM Project: iInsureU123 - k-Anonymity and anonymising data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b621b4b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " ## Overview\n",
    " In the notebook, we will implement functions to produce a k-anonymous customer information dataset provided by an insurance company, iInsureU123. The anonymised dataset would be made available to the researchers and government. Quasi-identifiers and sensitive attributes of values will be replaced with banded quantities to prevent sampled individuals from being identified. In addition, cryptographic hashing function will be applied to transform certain sensitive data to hash values for privacy reasons. The dataset will be made available to the public by the government whereas researchers from Imperial College will use the dataset for research purposes. Therefore, two datasets containing different attributes will be generated and encrypted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d386d9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading Dataframes\n",
    "In the project, we will use the Pandas package to load dataset as a data frame. Other modules that will be used have been listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ced9379f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Packages loading\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import hashlib\n",
    "import random, string\n",
    "from cryptography.fernet import Fernet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed777f08",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reading the raw data \"customer_information.csv\" in as a dataframe with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2bfb15da",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import data and target\n",
    "df = pd.read_csv('customer_information.csv') #Using relative path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ba9c4d1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Banding\n",
    "The utility of the dataset depends is based around exploring the association of the gene DRD4 and the exposures of travelling, education and geographical location. However, individual height and weight may be not necessary for the research purposes. We decide to convert height and weight into BMI for both research and privacy-preserving reasons, since the utility is maintained whilst improving anonymity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cc336c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting columns \"weight\" and \"height\" into numeric.\n",
    "df[\"weight\"] = pd.to_numeric(df[\"weight\"])\n",
    "df[\"height\"] = pd.to_numeric(df[\"height\"])\n",
    "df['heightsquared']=df['height']**2\n",
    "\n",
    "#Converting to BMI\n",
    "df['bmi']=df['weight']/df['heightsquared']\n",
    "df['bmi']=df['bmi'].apply(lambda x:round(x,2))\n",
    "\n",
    "#Deleting the intermediate column 'heightsquared'\n",
    "del df['heightsquared']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19adc461",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the following section, values of quasi-identifiers and sensitive attributes will be banded. For example, birthdate will be converted to banded age groups; participants will be categorized into light, intermediate and heavy smokers according to average cigarettes smoked per week; consumption of drinks will be categorized to low-level, moderate and high-level alcoholic consumption; participants will be grouped to \"underweight\",\"healthy\" and \"overweight\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4811011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a function to convert birthdate to age group\n",
    "#Intermediate year of birth column for calculating age\n",
    "birthdate=pd.to_datetime(df.birthdate)\n",
    "df['birth_year'] = pd.DatetimeIndex(birthdate).year\n",
    "\n",
    "#Age calculation\n",
    "def from_birthdate_to_age(birth_date):\n",
    "    now=pd.Timestamp('now')\n",
    "    now_year,now_month,now_day = now.year, now.month, now.day\n",
    "    birth_date = pd.to_datetime(birth_date)\n",
    "    birth_year, birth_month, birth_day = birth_date.year, birth_date.month, birth_date.day\n",
    "    age = now_year - birth_year\n",
    "    if now_month >= birth_month:\n",
    "        if now_day >= birth_day:\n",
    "            age = now_year - birth_year + 1\n",
    "    return (age)\n",
    "\n",
    "df['age'] = df['birthdate'].apply(from_birthdate_to_age)\n",
    "\n",
    "#Banding age to groups\n",
    "bins_age = [18,27,37,47,57,67]\n",
    "labels_age= ['18-27','28-37','38-47','48-57','58-67']\n",
    "df['age_groups'] = pd.cut(df.age, bins = bins_age, labels = labels_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1bb134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Banding smoking per week\n",
    "##We are defining smoking <=40 cig per week as light smokers, 40-175 as intermediate smokers, >175 as heavy smokers [(Schane et al., 2010)][(Wilson et al., 1992)]\n",
    "bins_smok= [0, 40, 175, 500]\n",
    "labels_smok=['light smokers','intermediate smokers','heavy smokers']\n",
    "df['smoking_status'] = pd.cut(df.avg_n_cigret_per_week, bins = bins_smok, labels = labels_smok)\n",
    "\n",
    "# Banding avg_n_drinks_per_week\n",
    "## 0-3.9 as low-level alc consumption, 4-6.9 as moderate alc consumption,7-10 as high-level alc consumption\n",
    "bins_alc = [0,4,7,10]\n",
    "label_alc = ['low', 'moderate', 'high']\n",
    "df['level of drinking_status'] = pd.cut(df.avg_n_drinks_per_week, bins = bins_alc, labels = label_alc, right = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a327fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding 'BMI' to groups\n",
    "##0-18.5 as underweight, 18.5-24.9 as healthy,24.9 and over as overweight\n",
    "\n",
    "bins_bmi = [0,18.5,24.9,50]\n",
    "label_bmi = ['Underweight','Healthy','Overweight']\n",
    "df['level of bmi'] = pd.cut(df.bmi, bins = bins_bmi, labels = label_bmi, right = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e204395",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The government aims to identify the association of genes and educational or geographical background. Therefore, country of birth and education levels are essential for the government dataset. In the following section, country of birth will be grouped by continents and cultural reasons because geographical and socio-cultural perspectives affect the decisions on migration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11b37199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country_of_birth mapping to continents\n",
    "import pycountry_convert as pc  #pip install pycountry-convert\n",
    "replace_dict={'Korea':'South Korea','Palestinian Territory':'Jordan','Saint Barthelemy':'Dominican Republic','Saint Helena': 'South Africa',\n",
    "'Reunion': 'Mauritius','Svalbard and Jan Mayen':'Greenland','United States Minor Outlying Islands':'United States',\n",
    "'Antarctica (the territory South of 60 deg S)': 'Heard Island and McDonald Islands','Western Sahara':'Morocco','Svalbard & Jan Mayen Islands':'Heard Island and McDonald Islands',\n",
    "'Libyan Arab Jamahiriya':'Libya','Pitcairn Islands':'Fiji','Slovakia (Slovak Republic)':'Slovakia','Bouvet Island (Bouvetoya)':'Heard Island and McDonald Islands',\n",
    "'Holy See (Vatican City State)':'Italy','Timor-Leste':'Indonesia',\"Cote d'Ivoire\":'Ghana','British Indian Ocean Territory (Chagos Archipelago)':'India',\n",
    "\"Netherlands Antilles\":\"Netherlands\"}\n",
    "df['country_of_birth'].replace(replace_dict,inplace=True)\n",
    "\n",
    "# Group original countries to continent by applying a function to dataframe\n",
    "def country_to_continent(country_of_birth):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_of_birth)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "df['continent_of_birth'] = df['country_of_birth'].apply(country_to_continent)\n",
    "\n",
    "# Group some continents according to geographic / cultural reasons to improve K-anonymity\n",
    "df['continent_of_birth'].replace({'North America':'America','South America':'America','Antarctica':'Europe'},inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e6d679c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the following section, we band the education level into three groups. Primary and secondary education will be grouped to pre-university whereas masters and phD will be identified as post-graduate qualification. As apprenticeship or diploma are not included in the list, we assume that other degree could contain these academic qualification which then should be categorized as bachelor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4cd69198",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Banding of education\n",
    "df['education_level'].replace({'secondary':'pre-uni',\n",
    "'primary': 'pre-uni',\n",
    "'bachelor': 'bachelor',\n",
    "'other': 'bachelor',\n",
    "'masters': 'post-grad',\n",
    "'phD':'post-grad'},inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87f8fa31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Secure Hashing Algorithm\n",
    "In the section below, we will create pseudonyms to anonymize direct sensitive identifiers (e.g. names, national insurance numbers). Secure Hashing Algorithm (SHA) will be used to map personal identifiers into a hashed pseudonym. In addition to SHA, we also add a salt i.e. random number generated by the computer to enhance the security, as well as a key to increase the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab47490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay_g\\AppData\\Local\\Temp\\ipykernel_21232\\4282430176.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['hash']=df['hash']\n",
      "C:\\Users\\jay_g\\AppData\\Local\\Temp\\ipykernel_21232\\4282430176.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['salt']=salt\n",
      "C:\\Users\\jay_g\\AppData\\Local\\Temp\\ipykernel_21232\\4282430176.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df.drop(columns=['age','birth_year','bmi'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#SHA \n",
    "#Salt generator\n",
    "def randomword(length):\n",
    "   letters = string.ascii_lowercase #generates lowercase letters\n",
    "   return ''.join(random.choice(letters) for i in range(length)) #generates salt from letters\n",
    "\n",
    "df['NI_enc']=df['national_insurance_number'].str.encode('utf-8') #utf encoding needed for sha function\n",
    "\n",
    "key='h8jij4f3'.encode('utf-8') #encoding key\n",
    "\n",
    "#Hash function\n",
    "hashes=[]\n",
    "salt=[]\n",
    "for i in range(len(df['NI_enc'])):\n",
    "    salt.append(randomword(10).encode('utf-8'))\n",
    "    hashes.append(hashlib.sha1(key+salt[i]+df['NI_enc'][i]).hexdigest()) #hash function applied \n",
    "\n",
    "df['hash']=hashes \n",
    "hash_cols=['given_name','surname','phone_number','national_insurance_number','blood_group',\n",
    "'postcode','birthdate','age','bank_account_number','birth_year','avg_n_drinks_per_week',\n",
    "'avg_n_cigret_per_week','bmi','country_of_birth','height','weight']\n",
    "\n",
    "#Lookup table generation\n",
    "secure_df=df[hash_cols]\n",
    "secure_df['hash']=df['hash']\n",
    "secure_df['salt']=salt\n",
    "secure_df.drop(columns=['age','birth_year','bmi'],inplace=True)\n",
    "secure_df.set_index('hash',inplace=True)#This is the sensitive dataset that is not shared\n",
    "new_cust=df.drop(columns=hash_cols)\n",
    "new_cust=new_cust.drop(columns='NI_enc')\n",
    "new_cust.set_index('hash',inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da936fdd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Calculating K-anonymity\n",
    "K-anonymity is computed based on processed data in order to assess the dataset's confidentiality in information sharing in the public domain. In the following sectioin, we calculate the k-anonminity for both researchers at Imperial College and the government's dataset. Due to the differences in research purposes, the dataset will contain different attributes as discussed previously. As a result quasi-identifiers differ in each anonymised dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1d26e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Imperial K-anonyminity is: 17\n",
      "The Government K-anonyminity is: 6\n"
     ]
    }
   ],
   "source": [
    "# K-anonyminity for Imperial dataset\n",
    "quasi_identifiers_imp=['age_groups','level of bmi','gender']\n",
    "k_df_imp=new_cust.groupby(quasi_identifiers_imp,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Imperial K-anonyminity is: {min(k_df_imp[\"Count\"])}')\n",
    "\n",
    "# K-anonyminity for government dataset\n",
    "quasi_identifiers_gov=['level of bmi','continent_of_birth','education_level']\n",
    "k_df_gov=new_cust.groupby(quasi_identifiers_gov,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Government K-anonyminity is: {min(k_df_gov[\"Count\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a52226",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here, we will export anonymised dataframe to CSV File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57760b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into csv\n",
    "imp_df=new_cust[['gender','age_groups','n_countries_visited','cc_status','level of bmi','level of drinking_status','smoking_status']]\n",
    "gov_df=new_cust[['continent_of_birth','education_level','cc_status','level of bmi','level of drinking_status','smoking_status']]\n",
    "imp_df.to_csv('Imperial Researchers Dataset.csv')\n",
    "gov_df.to_csv('Government Dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "476978be",
   "metadata": {},
   "source": [
    "## Secure File Generation via Encryption\n",
    "Creating keys for encrypting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e77400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key generation \n",
    "key = Fernet.generate_key()\n",
    "\n",
    "# string the key in a file\n",
    "with open ('filekey.key', 'wb') as filekey:\n",
    "    filekey.write(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245026b",
   "metadata": {},
   "source": [
    "Encryption for the Imperial Researchers Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32fd3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the key \n",
    "with open ('filekey.key', 'rb') as filekey:\n",
    "    key = filekey.read()\n",
    "\n",
    "# using the generated key \n",
    "fernet = Fernet (key)\n",
    "\n",
    "# opening the original file to encrypt\n",
    "with open('Imperial Researchers Dataset.csv', 'rb') as Imperial_Researchers_Dataset_file:\n",
    "    original = Imperial_Researchers_Dataset_file.read()\n",
    "\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the encrypted data\n",
    "with open ('Imperial Researchers Dataset.csv', 'wb') as encrypted_Imperial_Researchers_Dataset_file:\n",
    "    encrypted_Imperial_Researchers_Dataset_file.write(encrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e83e9b",
   "metadata": {},
   "source": [
    "Encryption for the Government Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc22eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the key \n",
    "with open ('filekey.key', 'rb') as filekey:\n",
    "    key = filekey.read()\n",
    "\n",
    "# using the generated key \n",
    "fernet = Fernet (key)\n",
    "\n",
    "# opening the original file to encrypt\n",
    "with open('Government Dataset.csv', 'rb') as Government_Dataset_file:\n",
    "    original = Government_Dataset_file.read()\n",
    "\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the encrypted data\n",
    "with open ('Government Dataset.csv', 'wb') as encrypted_Government_Dataset_file:\n",
    "    encrypted_Government_Dataset_file.write(encrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf277a",
   "metadata": {},
   "source": [
    "Instructions for decrypting the Imperial Researchers Dataset csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1882ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the key\n",
    "fernet = Fernet(key)\n",
    "\n",
    "\n",
    "# opening the encrypted file\n",
    "with open ('Imperial Researchers Dataset.csv', 'rb') as enc_Imperial_Researchers_Dataset_file:\n",
    "  encrypted = enc_Imperial_Researchers_Dataset_file.read()\n",
    "\n",
    "\n",
    "# decrypting the file\n",
    "decrypted = fernet.decrypt(encrypted)\n",
    "\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the decrypted data\n",
    "with open('Imperial Researchers Dataset.csv', 'wb') as dec_Imperial_Researchers_Dataset_file:\n",
    "  dec_Imperial_Researchers_Dataset_file.write(decrypted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf7d58",
   "metadata": {},
   "source": [
    "Instructions for decrypting the Government Dataset csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7595780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the key\n",
    "fernet = Fernet(key)\n",
    "\n",
    "\n",
    "# opening the encrypted file\n",
    "with open ('Government Dataset.csv', 'rb') as enc_Government_Dataset_file:\n",
    "  encrypted = enc_Government_Dataset_file.read()\n",
    "\n",
    "\n",
    "# decrypting the file\n",
    "decrypted = fernet.decrypt(encrypted)\n",
    "\n",
    "\n",
    "# opening the file in write mode and \n",
    "# writing the decrypted data\n",
    "with open('Government Dataset.csv', 'wb') as dec_Government_Dataset_file:\n",
    "  dec_Government_Dataset_file.write(decrypted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "423ff7d86d9cbe044ac35b20909f65b692966f7168e9bcbf4810c5e82eff1ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
