{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "CDM Project: iInsureU123 - k-Anonymity and anonymise the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Overview\n",
    " In the notebook, we will implement functions to produce a k-anonymous customer information dataset provided by an insurance company, iInsureU123. The anonymised dataset would be made available to the researchers and government. Quasi-identifiers and sensitive attributes of values will be replaced with banded quantities to prevent sampled individuals from being identified. In addition, cryptographic hashing function will be applied to transform certain sensitive data to hash values for privacy reasons. The dataset will be made available to public by government whereas researchers from Imperial College will use dataset for research purposes. Therefore, two dataset containing different attributes will be generated and encrypted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the project, we will use the Pandas to load dataset as a data frame. Other modules will be used have been listed as below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced9379f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Packages loading\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import hashlib\n",
    "import random, string"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the raw data \"customer_information\" in csv as a dataframe with Pandas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bfb15da",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import data and target\n",
    "df = pd.read_csv('customer_information.csv') #change to own source's directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset are used for research on the association of the gene DRD4 and travelling from educational or geographical perspective. However, individual height and weight may be not helpful for the research purpose. We decide to convert height and weight into BMI for both research purposes and privacy-preserving reason."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cc336c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert just colums \"weight\" and \"height\" into numeric.\n",
    "df[\"weight\"] = pd.to_numeric(df[\"weight\"])\n",
    "df[\"height\"] = pd.to_numeric(df[\"height\"])\n",
    "df['heightsquared']=df['height']**2\n",
    "\n",
    "#df.insert(1,\"BMI\",[])\n",
    "df['bmi']=df['weight']/df['heightsquared']\n",
    "df['bmi']=df['bmi'].apply(lambda x:round(x,2))\n",
    "\n",
    "# delete the column 'weight','height'and 'heightsquared'\n",
    "del df['weight']\n",
    "del df['height']\n",
    "del df['heightsquared']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following section, values of quasi identifiers and sensitive attributes in k-anonymous group will be banded. For example, birthdate will be converted to banded age groups; participants will be categorized into light, intermediate and heavy smokers according to average cigarettes smoked per week; consumption of drinks will be categorized to low-level, moderate and high-level alcoholic consumption; participants will be grouped to \"underweight\",\"healthy\" and \"overweight\"; countries visited will be banded into 3 groups."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4811011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a function to convert birthdate to age group\n",
    "# Years of birth\n",
    "birthdate=pd.to_datetime(df.birthdate)\n",
    "df['birth_year'] = pd.DatetimeIndex(birthdate).year\n",
    "\n",
    "# Age\n",
    "def from_birthdate_to_age(birth_date):\n",
    "    now=pd.Timestamp('now')\n",
    "    now_year,now_month,now_day = now.year, now.month, now.day\n",
    "    birth_date = pd.to_datetime(birth_date)\n",
    "    birth_year, birth_month, birth_day = birth_date.year, birth_date.month, birth_date.day\n",
    "    age = now_year - birth_year\n",
    "    if now_month >= birth_month:\n",
    "        if now_day >= birth_day:\n",
    "            age = now_year - birth_year + 1\n",
    "    return (age)\n",
    "\n",
    "df['age'] = df['birthdate'].apply(from_birthdate_to_age)\n",
    "\n",
    "# Banding age to groups\n",
    "bins_age = [18,27,37,47,57,67]\n",
    "labels_age= ['18-27','28-37','38-47','48-57','58-67']\n",
    "df['age_groups'] = pd.cut(df.age, bins = bins_age, labels = labels_age)\n",
    "\n",
    "# Banding age to groups\n",
    "bins_age_gov = [18,37,58,67]\n",
    "labels_age_gov= ['18-38','39-58','59-68']\n",
    "df['age_groups_gov'] = pd.cut(df.age, bins = bins_age_gov, labels = labels_age_gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bb134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding smoking per week\n",
    "## we are defining smoking <=40 cig per week as light smokers, 40-175 as intermediate smokers, >175 as heavy smokers [(Schane et al., 2010)][(Wilson et al., 1992)]\n",
    "bins_smok= [0, 40, 175, 500]\n",
    "labels_smok=['light smokers','intermediate smokers','heavy smokers']\n",
    "df['smoking_status'] = pd.cut(df.avg_n_cigret_per_week, bins = bins_smok, labels = labels_smok)\n",
    "\n",
    "# Banding avg_n_drinks_per_week\n",
    "## 0-3.9 as low-level alc consumption, 4-6.9 as moderate alc consumption,7-10 as high-level alc consumption\n",
    "bins_alc = [0,4,7,10]\n",
    "label_alc = ['low', 'moderate', 'high']\n",
    "df['level of drinking_status'] = pd.cut(df.avg_n_drinks_per_week, bins = bins_alc, labels = label_alc, right = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a327fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banding 'BMI' to groups\n",
    "## 0-18.5 as underweight, 18.5-24.9 as healthy,24.9 and over as overweight\n",
    "\n",
    "bins_bmi = [0,18.5,24.9,50]\n",
    "label_bmi = ['Underweight','Healthy','Overweight']\n",
    "df['level of bmi'] = pd.cut(df.bmi, bins = bins_bmi, labels = label_bmi, right = False)\n",
    "\n",
    "# Banding countries visited to groups\n",
    "bins_countries = [1, 18, 34, 50]\n",
    "labels_countries= ['2-18','19-34','35-50']\n",
    "df['countries_visited'] = pd.cut(df.n_countries_visited, bins = bins_countries, labels = labels_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The government aims to identify the association of genes and educational or geographical background. Therefore,country of birth and education levels are essential for government. In the following section, country of birth will be grouped by continents and cultural reasons because geographical and socio-cultural perspectives affect the decisions on migration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11b37199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country_of_birth Clearing Up\n",
    "import pycountry_convert as pc  #pip install pycountry-convert\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Korea'], 'South Korea')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Palestinian Territory'], 'Jordan')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Saint Barthelemy'], 'Dominican Republic')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Saint Helena'], 'South Africa')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Reunion'], 'Mauritius')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Svalbard and Jan Mayen'], 'Greenland')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['United States Minor Outlying Islands'], 'United States')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Antarctica (the territory South of 60 deg S)'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Western Sahara'], 'Morocco')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Svalbard & Jan Mayen Islands'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Libyan Arab Jamahiriya'], 'Libya')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Pitcairn Islands'], 'Fiji')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Slovakia (Slovak Republic)'], 'Slovakia')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Bouvet Island (Bouvetoya)'], 'Heard Island and McDonald Islands')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Holy See (Vatican City State)'], 'Italy')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['Timor-Leste'], 'Indonesia')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace([\"Cote d'Ivoire\"], 'Ghana')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace(['British Indian Ocean Territory (Chagos Archipelago)'], 'India')\n",
    "df['country_of_birth'] = df['country_of_birth'].replace([\"Netherlands Antilles\"], \"Netherlands\")\n",
    "\n",
    "# Group original countries to continent by applying a function to dataframe\n",
    "def country_to_continent(country_of_birth):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_of_birth)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "df['continent_of_birth'] = df['country_of_birth'].apply(country_to_continent)\n",
    "\n",
    "# Group some continents according to geographic / cultural reasons\n",
    "df['continent_of_birth'] = df['continent_of_birth'].replace(['North America'], 'America')\n",
    "df['continent_of_birth'] = df['continent_of_birth'].replace(['South America'], 'America')\n",
    "df['continent_of_birth'] = df['continent_of_birth'].replace(['Antarctica'], 'Europe')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following section, we band the education level into three group. Primary and secondary education will be grouped to pre-university whereas masters and phD will be identified as post-graduate qualification. As apprenticeship or diploma are not included in the list, we assume that other degree could contain these academic qualification which then should be categorized as bachelor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4cd69198",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Banding\n",
    "df['education_level'] = df['education_level'].replace(['secondary'],'pre-uni')\n",
    "df['education_level'] = df['education_level'].replace(['primary'], 'pre-uni')\n",
    "df['education_level'] = df['education_level'].replace(['bachelor'], 'bachelor')\n",
    "df['education_level'] = df['education_level'].replace(['other'], 'bachelor')\n",
    "df['education_level'] = df['education_level'].replace(['masters'], 'post-grad')\n",
    "df['education_level'] = df['education_level'].replace(['phD'], 'post-grad')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the section below, we will create pseudonyms to anonymize direct sensitive identifiers (e.g. names, national insurance numbers). Secure Hashing Algorithm (SHA) will be used to map personal identifiers into a non-identifiable strings. In addition to SHA, we also add a salt i.e. random number generated by the computer to enhance the security."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab47490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jay_g\\AppData\\Local\\Temp\\ipykernel_12592\\2780082543.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['hash']=df['hash']\n",
      "C:\\Users\\jay_g\\AppData\\Local\\Temp\\ipykernel_12592\\2780082543.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  secure_df['salt']=salt\n"
     ]
    }
   ],
   "source": [
    "#SHA ----------------------------------------------------------------\n",
    "\n",
    "#Salt generator\n",
    "def randomword(length):\n",
    "   letters = string.ascii_lowercase #generates lowercase letters\n",
    "   return ''.join(random.choice(letters) for i in range(length)) #generates salt from letters\n",
    "\n",
    "df['NI_enc']=df['national_insurance_number'].str.encode('utf-8') #utf encoding needed for sha function\n",
    "\n",
    "key='password123'.encode('utf-8') #encoding key\n",
    "\n",
    "#Hash function\n",
    "hashes=[]\n",
    "salt=[]\n",
    "for i in range(len(df['NI_enc'])):\n",
    "    salt.append(randomword(10).encode('utf-8'))\n",
    "    hashes.append(hashlib.sha1(key+salt[i]+df['NI_enc'][i]).hexdigest()) #hash function applied \n",
    "\n",
    "df['hash']=hashes\n",
    "df['postcode_split'] = df['postcode'].str.split().str[0] \n",
    "hash_cols=['given_name','surname','phone_number','national_insurance_number','blood_group','postcode','birthdate','age','bank_account_number','birth_year','avg_n_drinks_per_week','avg_n_cigret_per_week','n_countries_visited','bmi','country_of_birth']\n",
    "\n",
    "#Lookup table generation\n",
    "secure_df=df[hash_cols]\n",
    "secure_df['hash']=df['hash']\n",
    "secure_df['salt']=salt\n",
    "new_cust=df.drop(columns=hash_cols)\n",
    "new_cust=new_cust.drop(columns='NI_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-anonymity is computed based on processed data in order to secure the dataset's confidentiality in information sharing in public. In the situation, the database is said to become K Anonymous. In the following sectioin, we calculate the k-anonminity for both researchers at Imperial College and government. Due to the difference in research purposes, dataset will contain different attributes as discussed previously. As a result. quasi identifiers differ in each anonymised dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d26e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Imperial K-anonyminity is: 17\n",
      "The Government K-anonyminity is: 6\n"
     ]
    }
   ],
   "source": [
    "# K-anonyminity - Currently freezes when adding any more quasi_identifiers\n",
    "quasi_identifiers_imp=['age_groups','level of bmi','gender']\n",
    "k_df_imp=new_cust.groupby(quasi_identifiers_imp,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Imperial K-anonyminity is: {min(k_df_imp[\"Count\"])}')\n",
    "\n",
    "# K-anonyminity - Currently freezes when adding any more quasi_identifiers\n",
    "quasi_identifiers_gov=['level of bmi','continent_of_birth','education_level']\n",
    "k_df_gov=new_cust.groupby(quasi_identifiers_gov,observed=True).size().reset_index(name='Count').sort_values(by='Count')\n",
    "print(f'The Government K-anonyminity is: {min(k_df_gov[\"Count\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we will export anonymised dataframe to CSV File."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57760b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into csv\n",
    "new_cust.to_csv('new_cust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8f3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c84df20ab1ac10669529321b7ccb4b2c6d7ae7eb8b375dacb72b7198d4c273e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
